band            : 10000000.0
buffer_size     : 100000
core0_load      : 1.0
core1_load      : 1.0
demand_max      : 30000000.0
demand_min      : 20000000.0
dir_log         : ./dev\cran\data\log
dir_mod         : ./dev\cran\data\mod
dir_sum         : ./dev\cran\data\sum
episodes        : 100
epochs          : 10
epsilon_final   : 0.01
epsilon_init    : 0.5
epsilon_steps   : 4000
eta             : 0.25
gamma           : 0.99
load_diff       : 1.0
load_id         : None
load_max        : 1.0
load_min        : 1.0
lr              : 0.001
mini_batch      : 64
num_rrh         : 10
num_usr         : 8
observations    : 100
pow_gap         : 3.0
pow_on          : 6.8
pow_slp         : 4.3
pow_tsm         : 1.0
random_seed     : 10000
reward_util     : 1.0
run_id          : 12-04-00-46-53
save_ep         : 20
task_util       : 1.0
tests           : 10
theta_2         : 6.3095734448e-14
tm              : 1
update          : 8
| Episode: 20 | Demand: [2.905 2.869 2.494 2.401 2.819 2.946 2.084 2.542] | Epsilon: 0.4975 | Agent-steps: 200 | Length: before 200 after 200 | Ep-max-reward: 0.5950 | Ep-min-reward: 0.4174 | Ep-rnd-reward: 9 0.5053 | Ep-reward: 1.0111 | Ep-max-power: 72.0255 | Ep-min-power: 61.4602 | Ep-rnd-power: 77.9009 | Ep-power: 0.5050 | Num-rrh-on: 8 | Ep-action: [(1.0, 200)] | Init-state: 1-1-1-1-1-0-0-1-1-1 | Final-state: 1-1-1-1-1-0-0-1-1-1
| Episode: 40 | Demand: [2.229 2.087 2.468 2.05  2.351 2.726 2.867 2.625] | Epsilon: 0.4951 | Agent-steps: 400 | Length: before 200 after 200 | Ep-max-reward: 0.5952 | Ep-min-reward: 0.4406 | Ep-rnd-reward: 9 0.5323 | Ep-reward: 1.2000 | Ep-max-power: 72.0155 | Ep-min-power: 59.9399 | Ep-rnd-power: 76.1361 | Ep-power: 0.5900 | Num-rrh-on: 4 | Ep-action: [(1.0, 200)] | Init-state: 1-0-0-1-0-1-1-0-0-0 | Final-state: 1-0-0-1-0-1-1-0-0-0
| Episode: 60 | Demand: [2.592 2.768 2.307 2.537 2.045 2.194 2.273 2.472] | Epsilon: 0.4926 | Agent-steps: 600 | Length: before 200 after 200 | Ep-max-reward: 0.5979 | Ep-min-reward: 0.5435 | Ep-rnd-reward: 8 0.4811 | Ep-reward: 0.8511 | Ep-max-power: 71.8396 | Ep-min-power: 75.3993 | Ep-rnd-power: 79.4895 | Ep-power: 0.4330 | Num-rrh-on: 7 | Ep-action: [(1.0, 200)] | Init-state: 1-1-1-1-1-0-0-1-1-0 | Final-state: 1-1-1-1-1-0-0-1-1-0
| Episode: 80 | Demand: [2.314 2.611 2.716 2.076 2.002 2.573 2.64  2.496] | Epsilon: 0.4902 | Agent-steps: 800 | Length: before 200 after 200 | Ep-max-reward: 0.5970 | Ep-min-reward: 0.3662 | Ep-rnd-reward: 8 0.5035 | Ep-reward: 1.1822 | Ep-max-power: 71.8984 | Ep-min-power: 53.7119 | Ep-rnd-power: 78.0213 | Ep-power: 0.5820 | Num-rrh-on: 4 | Ep-action: [(1.0, 200)] | Init-state: 0-0-1-1-1-0-0-0-0-1 | Final-state: 0-0-1-1-1-0-0-0-0-1
