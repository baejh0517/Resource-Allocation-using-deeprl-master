band            : 10000000.0
buffer_size     : 100000
core0_load      : 0.0
core1_load      : 0.0
demand_max      : 4.0
demand_min      : 3.5
dir_log         : ./dev/cran/data/log
dir_mod         : ./dev/cran/data/mod
dir_sum         : ./dev/cran/data/sum
episodes        : 100
epochs          : 30
epsilon_final   : 0.01
epsilon_init    : 0.5
epsilon_steps   : 4000
eta             : 0.25
gamma           : 0.99
load_diff       : 1.0
load_id         : None
load_max        : 1.0
load_min        : 1.0
lr              : 0.2
mini_batch      : 64
num_rrh         : 12
num_usr         : 6
observations    : 100
pow_gap         : 3.0
pow_on          : 6.8
pow_slp         : 4.3
pow_tsm         : 1.0
random_seed     : 10000
reward_util     : 1.0
run_id          : 12-12-13-11-49
save_ep         : 20
task_num        : 1.0
task_util       : 1.0
tests           : 10
theta_2         : 6.3095734448e-14
tm              : 1
update          : 8
| Episode: 20 | Demand: [0. 0. 0. 0. 0. 0.] | Epsilon: 0.4975 | Agent-steps: 600 | Length: before 600 after 600 | Ep-max-reward: 0.6497 | Ep-min-reward: 0.6497 | Ep-rnd-reward: 1 1.0000 | Ep-reward: -0.1095 | Ep-max-power: 81.6000 | Ep-min-power: 81.6000 | Ep-rnd-power: 54.1000 | Ep-power: 1.1095 | Num-rrh-on: 4 | Ep-action: [(1.0, 600)] | Init-state: 0-2-0-0-1-0-3-1-1-0-1-2 | Final-state: 0-2-0-0-1-0-3-1-1-0-1-2
| Episode: 40 | Demand: [0. 0. 0. 0. 0. 0.] | Epsilon: 0.4951 | Agent-steps: 1200 | Length: before 600 after 600 | Ep-max-reward: 0.6497 | Ep-min-reward: 0.6497 | Ep-rnd-reward: 1 1.0000 | Ep-reward: 0.2729 | Ep-max-power: 81.6000 | Ep-min-power: 81.6000 | Ep-rnd-power: 54.1000 | Ep-power: 0.7271 | Num-rrh-on: 1 | Ep-action: [(1.0, 600)] | Init-state: 3-3-2-1-0-3-3-3-2-2-2-0 | Final-state: 3-3-2-1-0-3-3-3-2-2-2-0
| Episode: 60 | Demand: [0. 0. 0. 0. 0. 0.] | Epsilon: 0.4926 | Agent-steps: 1800 | Length: before 600 after 600 | Ep-max-reward: 0.6497 | Ep-min-reward: 0.6497 | Ep-rnd-reward: 1 1.0000 | Ep-reward: 0.2716 | Ep-max-power: 81.6000 | Ep-min-power: 81.6000 | Ep-rnd-power: 54.1000 | Ep-power: 0.7284 | Num-rrh-on: 3 | Ep-action: [(1.0, 600)] | Init-state: 1-0-1-3-3-2-0-3-2-0-3-1 | Final-state: 1-0-1-3-3-2-0-3-2-0-3-1
| Episode: 80 | Demand: [0. 0. 0. 0. 0. 0.] | Epsilon: 0.4902 | Agent-steps: 2400 | Length: before 600 after 600 | Ep-max-reward: 0.6497 | Ep-min-reward: 0.6497 | Ep-rnd-reward: 1 1.0000 | Ep-reward: 0.2065 | Ep-max-power: 81.6000 | Ep-min-power: 81.6000 | Ep-rnd-power: 54.1000 | Ep-power: 0.7935 | Num-rrh-on: 4 | Ep-action: [(1.0, 600)] | Init-state: 0-3-2-2-0-0-1-1-1-2-0-1 | Final-state: 0-3-2-2-0-0-1-1-1-2-0-1
| Episode: 100 | Demand: [0. 0. 0. 0. 0. 0.] | Epsilon: 0.4877 | Agent-steps: 3000 | Length: before 600 after 600 | Ep-max-reward: 0.6497 | Ep-min-reward: 0.6497 | Ep-rnd-reward: 1 1.0000 | Ep-reward: 0.2160 | Ep-max-power: 81.6000 | Ep-min-power: 81.6000 | Ep-rnd-power: 54.1000 | Ep-power: 0.7840 | Num-rrh-on: 4 | Ep-action: [(1.0, 600)] | Init-state: 0-3-3-1-0-1-0-3-1-1-2-2 | Final-state: 0-3-3-1-0-1-0-3-1-1-2-2
